{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "docs = ['this this this book',\n",
    "        'this cat good',\n",
    "        'cat good shit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count(docs):\n",
    "    count_model = CountVectorizer(ngram_range=(1,1))\n",
    "    X = count_model.fit_transform(docs)\n",
    "    Xc = (X.T * X)\n",
    "    print (Xc.shape)\n",
    "    print(count_model.get_feature_names())\n",
    "    print(Xc.todense())\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_model = CountVectorizer(ngram_range=(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  0  0  0  0  0  3  1  0  2]\n",
      " [ 0  2  2  2  1  1  1  0  1  0]\n",
      " [ 0  2  2  2  1  1  1  0  1  0]\n",
      " [ 0  2  2  2  1  1  1  0  1  0]\n",
      " [ 0  1  1  1  1  1  0  0  0  0]\n",
      " [ 0  1  1  1  1  1  0  0  0  0]\n",
      " [ 3  1  1  1  0  0 10  3  1  6]\n",
      " [ 1  0  0  0  0  0  3  1  0  2]\n",
      " [ 0  1  1  1  0  0  1  0  1  0]\n",
      " [ 2  0  0  0  0  0  6  2  0  4]]\n"
     ]
    }
   ],
   "source": [
    "X = count_model.fit_transform(docs)\n",
    "Xc = (X.T * X)\n",
    "print(Xc.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "trails = ['Ram','1','shyam','hari']\n",
    "\n",
    "# \\b means word boundaries.\n",
    "regex = r\"\\b(?:{})\\b\".format(\"|\".join(trails))\n",
    "\n",
    "s = \"Ram is number 1 than hari\"\n",
    "\n",
    "res = re.split(regex, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', ' is number ', ' than ', '']\n"
     ]
    }
   ],
   "source": [
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import stopwords\n",
    "import re\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "stopwords = open(\"stopwords.txt\").read().splitlines()\n",
    "def loadData(loc):\n",
    "        BASEDIR=os.path.dirname(os.path.realpath('__file__'))\n",
    "        df=pd.read_csv(BASEDIR+loc,names=[\"headline\",\"news\"])\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=loadData(\"/dataset/onlineKhabar.csv\")\n",
    "REPLACE_BY_SPACE_RE = re.compile('[?!/(){}\\[\\]\\|@,;\\'\\']')\n",
    "def removeCharacs(text):\n",
    "    text=re.sub(REPLACE_BY_SPACE_RE,' ',text)# replace REPLACE_BY_SPACE_RE symbols by space in text\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten = lambda x : ''.join(x.split('\\','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['news'] = df['news'].map(flatten).map(removeCharacs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_text_cat2(text):\n",
    "    return re.sub('(मा|को|ले|बाट|का|हरु|हरुसँग|सँग|लाई|हरू|हरूसँग|हरू)','',text)\n",
    "allwords = open(\"dict.txt\").read().splitlines()\n",
    "suffixes = ('ी' , 'ीया' ,  'ीय' ,'े' , 'नु' , 'दै' , 'ेको' , 'ै')\n",
    "def stem_text_cat1(word):\n",
    "    if word.endswith(suffixes):\n",
    "        wordlist =  [word.rstrip(x) for x in suffixes]\n",
    "        for i in wordlist:\n",
    "            if i!= word:\n",
    "                if i in allwords:\n",
    "                    return i\n",
    "                    \n",
    "        \n",
    "    return word\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming(text):\n",
    "    text =  ' '.join([stem_text_cat1(a) for a in word_tokenize(text)])\n",
    "    return ' '.join([stem_text_cat2(a) for a in word_tokenize(text)])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['news'] = df['news'].map(stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_tokenize(text):\n",
    "    sentence = [x for x in text.split('।')] \n",
    "    return sentence\n",
    "df['news-ws']=df['news'].map(sent_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to remove stopwords\n",
    "def remove_stopword(sen):\n",
    "    sen_new = \" \".join([i for i in sen if i not in stopwords])\n",
    "    return sen_new\n",
    "remove_stopwords = lambda sent : [remove_stopword(r.split()) for r in sent]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['news-ws'] = df['news-ws'].map(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['विश्व नम्वर वान टेक कम्पनी एप्पल निस प्रमुख र्यरी अधिकृत सिइओ पाउन तलब भत्ता चानचुने कुरै',\n",
       " 'त्यसै एप्पल वर्तन सिइओ टिम कुक गत वर्ष सन् २०१५ १ अर्ब रुपैयाँ बढि वाषिर्क तलबभत्ता बुझे',\n",
       " 'अघिल्लो वर्ष तुलना सन् २०१५ कुक तलब भत्ता ११.५ प्रतिशत वृद्धि',\n",
       " 'उन वर्ष एप्पल १ करोड ३ डलर रकम बुझे',\n",
       " 'कुक आधारभुत बेतन गत वर्ष १४.४ प्रतिशत २० करोड रुपैयाँ वृद्धि नन इक्विटी इन्सेन्टिभ १९ प्रतिशत वृद्धि ८० करोड रुपैयाँ पुगे',\n",
       " 'यतिधेरै तलब भत्ता थाप्न कुक एप्पल एकत्र कर्मचारी होलान् कर्मचारी तलब उन निक भन्न सोँच्नुहोला',\n",
       " 'अचम्म एप्पल उच्च पदस्थ र्यरीमध्ये कुक पाए तलब भत्ता सबैभन्दा',\n",
       " 'कम्पनी प्रमुख वित्तिय अधिकृत लू वाषिर्क तलब ८१ प्रतिशत वृद्धि उन गत वर्ष अढाइ अर्ब रुपैयाँ बढि तलब भत्ता बुझे',\n",
       " 'रिटेल एण्ड अनलाइन स्टोर वरिष्ठ उपाध्यक्ष एन्जेला गत वर्ष एप्पल सबैभन्दा बढि तलब भत्ता बुझ्ने कर्मचारी',\n",
       " 'उन गत वर्ष उन २ अर्ब ६० करोड रुपैयाँ बढि तलब भत्ता बुझेकी छिन्',\n",
       " 'गत वर्ष सन् २०१५ एप्पलल बिक्रि २८ प्रतिशत बढ्यो मुनाफा ३५ प्रतिशत बढे बताइए',\n",
       " 'सन् २००८ यता पहिलोपटक एप्पलल शेयर मूल्य गिरावट',\n",
       " '']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['news-ws'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 6)\n",
      "['उन', 'नम', 'पटक', 'पह', 'यत', 'वर']\n",
      "[[1 0 0 0 0 1]\n",
      " [0 1 0 0 0 1]\n",
      " [0 0 1 1 1 0]\n",
      " [0 0 1 1 1 0]\n",
      " [0 0 1 1 1 0]\n",
      " [1 1 0 0 0 2]]\n"
     ]
    }
   ],
   "source": [
    "count([\"विश्व नम्वर\",\"उन वर्ष\",\"यता पहिलोपटक\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findCandidates(text):\n",
    "    clusters=[]\n",
    "    word1=[]\n",
    "    for word in word_tokenize(text):\n",
    "        if word in stopwords:\n",
    "            clusters.append(word1)\n",
    "            word1 =[]\n",
    "            continue\n",
    "        else:\n",
    "            word1.append(word)\n",
    "    return [' '.join(a).replace('।','') for a in clusters if len(a)>1]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['kW-candidates'] = df['news'].map(findCandidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
